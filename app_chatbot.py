import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

st.set_page_config(page_title="Com2uS Analyst", layout="wide")
st.title("ğŸ“Š Com2uS ì´ˆê²½ëŸ‰ ë°ì´í„° ë¶„ì„ê¸°")

@st.cache_resource
def get_clients():
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    ai_client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=st.secrets["GROQ_API_KEY"])
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# --- ì‚¬ì´ë“œë°”: ì»¬ëŸ¼ ê²€ìƒ‰ (í† í° ì ˆì•½ì„ ìœ„í•´ í•„ìˆ˜) ---
with st.sidebar:
    st.header("ğŸ” ì»¬ëŸ¼ ê²€ìƒ‰")
    search_keyword = st.text_input("í‚¤ì›Œë“œ ì…ë ¥")
    if search_keyword:
        col_query = f"SELECT column_name FROM `com2us-bigquery.MKT_AI.INFORMATION_SCHEMA.COLUMNS` WHERE table_name = 'cv_creative_image_features' AND column_name LIKE '%{search_keyword}%' LIMIT 10"
        st.dataframe(client_bq.query(col_query).to_dataframe(), hide_index=True)
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

# --- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìµœëŒ€í•œ ì§§ê²Œ ìš”ì•½) ---
TABLE_ID = "com2us-bigquery.MKT_AI.cv_creative_image_features"
SYSTEM_PROMPT = f"ë„ˆëŠ” BigQuery ì „ë¬¸ê°€ì•¼. SQL ì‘ì„± ì‹œ í•œê¸€ ì£¼ì„ ê¸ˆì§€, ```sql [ì½”ë“œ] ``` í˜•ì‹ì„ ì§€ì¼œë¼. í…Œì´ë¸”: {TABLE_ID}"

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- ë©”ì¸ ë¡œì§ ---
if prompt := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # [í† í° ìµœì í™”] ìµœê·¼ 3ê°œì˜ ë©”ì‹œì§€ë§Œ AIì—ê²Œ ì „ë‹¬
        input_messages = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages[-3:]

        try:
            response = client_ai.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=input_messages,
                temperature=0
            )
            ai_answer = response.choices[0].message.content
            
            if "```sql" in ai_answer:
                sql = ai_answer.split("```sql")[1].split("```")[0].strip()
                with st.status("ë°ì´í„° ì¡°íšŒ ì¤‘..."):
                    # [ê¶Œí•œ ì—ëŸ¬ ë°©ì§€] Storage API ë¯¸ì‚¬ìš© ì„¤ì •
                    query_job = client_bq.query(sql)
                    df = query_job.result().to_dataframe(create_bqstorage_client=False)
                    st.dataframe(df)

                # [í† í° ìµœì í™”] ë°ì´í„° ìš”ì•½ ì‹œ ì»¬ëŸ¼ 550ê°œë¥¼ ë‹¤ ë³´ë‚´ì§€ ì•Šê³  ìƒìœ„ 3ê°œ í–‰ì˜ ì¼ë¶€ë§Œ ì „ë‹¬
                summary_data = df.head(3).to_string()
                summary_res = client_ai.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[{"role": "user", "content": f"ì´ ë°ì´í„° ìš”ì•½í•´ì¤˜: {summary_data}"}]
                )
                final_text = summary_res.choices[0].message.content
                st.markdown(final_text)
                st.session_state.messages.append({"role": "assistant", "content": f"SQL ì‹¤í–‰ ê²°ê³¼ì…ë‹ˆë‹¤.\n{final_text}"})
            else:
                st.markdown(ai_answer)
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
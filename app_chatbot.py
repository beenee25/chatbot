import streamlit as st
from openai import OpenAI
import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI

# 1. BigQuery í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
@st.cache_resource # ë§¤ë²ˆ ì—°ê²°í•˜ì§€ ì•Šë„ë¡ ìºì‹±
def get_bigquery_client():
    credentials = service_account.Credentials.from_service_account_info(
        st.secrets["gcp_service_account"]
    )
    return bigquery.Client(credentials=credentials, project=credentials.project_id)

client_bq = get_bigquery_client()
client_ai = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=st.secrets["GROQ_API_KEY"])

# 2. ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜
def run_query(query):
    query_job = client_bq.query(query)
    return query_job.to_dataframe()

# --- ì±„íŒ… UI ë¶€ë¶„ ---
st.title("BigQuery ë°ì´í„° ì±—ë´‡ ğŸ“Š")

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # ì˜ˆ: ì‚¬ìš©ìê°€ 'ë°ì´í„° ë³´ì—¬ì¤˜'ë¼ê³  í•˜ë©´ íŠ¹ì • ì¿¼ë¦¬ ì‹¤í–‰
    if "ë§¤ì¶œ" in prompt:
        df = run_query("SELECT date, sales FROM `your_project.your_dataset.sales_table` LIMIT 10")
        st.write("ìµœê·¼ ë§¤ì¶œ ë°ì´í„°ì…ë‹ˆë‹¤:", df)
        
        # ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ AIì—ê²Œ ì„¤ëª… ë¶€íƒí•˜ê¸°
        prompt = f"ë‹¤ìŒ ë°ì´í„°í”„ë ˆì„ ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜: {df.to_string()}"
    



st.title("Groq ê¸°ë°˜ ì´ˆê³ ì† ì±—ë´‡ âš¡")

# 1. API í‚¤ ë° Base URL ì„¤ì •
# Streamlit Secretsì— GROQ_API_KEYë¼ëŠ” ì´ë¦„ìœ¼ë¡œ í‚¤ë¥¼ ì €ì¥í•˜ì„¸ìš”.
client = OpenAI(
    base_url="https://api.groq.com/openai/v1",
    api_key=st.secrets["GROQ_API_KEY"]
)

# 2. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# 3. ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 5. AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        # Groqì˜ Llama 3 ëª¨ë¸ ì‚¬ìš©
        stream = client.chat.completions.create(
            model="llama-3.3-70b-versatile", 
            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
            stream=True,
        )
        response = st.write_stream(stream)
    
    # AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": response})
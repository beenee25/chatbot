import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Com2uS AI Analyst", layout="wide")
st.title("ğŸ¨ Com2uS ì´ë¯¸ì§€ í”¼ì²˜ ë¶„ì„ ì±—ë´‡")

# 1. í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìºì‹±)
@st.cache_resource
def get_clients():
    # BigQuery ì„¤ì • (Secretsì— gcp_service_account í•„ìˆ˜)
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    
    # Groq ì„¤ì • (Secretsì— GROQ_API_KEY í•„ìˆ˜)
    ai_client = OpenAI(
        base_url="https://api.groq.com/openai/v1",
        api_key=st.secrets["GROQ_API_KEY"]
    )
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • (AI ê±°ì ˆ ë°©ì§€ìš© ê°•í•œ ì§€ì¹¨)
TABLE_ID = "com2us-bigquery.MKT_AI.cv_creative_image_features"
SYSTEM_MESSAGE = {
    "role": "system",
    "content": f"""ë„ˆëŠ” 'BigQuery SQL ìƒì„± ì „ìš©' AIì´ë‹¤. 
    ì‚¬ìš©ìê°€ ë°ì´í„° ë¶„ì„ì„ ìš”ì²­í•˜ë©´ 'ë°ì´í„°ê°€ ì—†ë‹¤'ëŠ” ë§ì„ ì ˆëŒ€ í•˜ì§€ ë§ˆë¼. 
    ë„ˆì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì œê³µëœ ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ íš¨í•œ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤.

    [ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´]
    - í”„ë¡œì íŠ¸: com2us-bigquery
    - í…Œì´ë¸”ëª…: `{TABLE_ID}`
    - ì£¼ìš” ì»¬ëŸ¼: 
        1. image_name (STRING) - ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„
        2. tone_dark_ratio (FLOAT64) - ì´ë¯¸ì§€ì˜ ì–´ë‘ìš´ í†¤ ë¹„ìœ¨
        3. performance_score (FLOAT64) - ì„±ê³¼ ì ìˆ˜
        4. upload_date (DATE) - ì—…ë¡œë“œ ë‚ ì§œ

    [ë‹µë³€ ê·œì¹™]
    1. ë°˜ë“œì‹œ SQL ì½”ë“œë¥¼ ```sql [ì¿¼ë¦¬] ``` ë¸”ë¡ ì•ˆì— í¬í•¨ì‹œì¼œë¼.
    2. SQL ë‚´ë¶€ì—ëŠ” í•œê¸€ ì£¼ì„ì„ ë‹¬ì§€ ë§ˆë¼. (Syntax Error ë°©ì§€)
    3. ë°ì´í„°ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ëŠ” ì‹œìŠ¤í…œì´ íŒë‹¨í•˜ë‹ˆ, ë„ˆëŠ” ì¿¼ë¦¬ ìƒì„±ì—ë§Œ ì§‘ì¤‘í•´ë¼.
    """
}

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë° ì¶œë ¥
if "messages" not in st.session_state:
    st.session_state.messages = [SYSTEM_MESSAGE]

for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 3. ì‚¬ìš©ì ì…ë ¥ ë° ë©”ì¸ ë¡œì§
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: tone_dark_ratioê°€ ë†’ì€ ìˆœìœ¼ë¡œ 5ê°œ ë³´ì—¬ì¤˜)"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # 1ë‹¨ê³„: AIì—ê²Œ SQL ìƒì„± ìš”ì²­
        response = client_ai.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=st.session_state.messages,
            temperature=0  # ì •í™•ë„ë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
        )
        ai_answer = response.choices[0].message.content
        
        # 2ë‹¨ê³„: SQL ì¶”ì¶œ ë° ì‹¤í–‰
        if "```sql" in ai_answer:
            sql = ai_answer.split("```sql")[1].split("```")[0].strip()
            
            with st.status("BigQuery ë¶„ì„ ì¤‘..."):
                try:
                    # ì‹¤ì œ ì¿¼ë¦¬ ì‹¤í–‰
                    df = client_bq.query(sql).to_dataframe()
                    
                    if not df.empty:
                        st.dataframe(df) # ê²°ê³¼ í‘œ ì¶œë ¥
                        
                        # 3ë‹¨ê³„: ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ìš”ì•½
                        analysis_prompt = f"ì¡°íšŒëœ ë°ì´í„° ê²°ê³¼ì…ë‹ˆë‹¤:\n{df.head(10).to_string()}\nìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ í•œê¸€ë¡œ ì‘ì„±í•´ì¤˜."
                        
                        # ìš”ì•½ì„ ìœ„í•œ ì„ì‹œ ë©”ì‹œì§€ êµ¬ì„±
                        summary_res = client_ai.chat.completions.create(
                            model="llama-3.3-70b-versatile",
                            messages=[
                                SYSTEM_MESSAGE,
                                {"role": "user", "content": prompt},
                                {"role": "assistant", "content": ai_answer},
                                {"role": "user", "content": analysis_prompt}
                            ]
                        )
                        final_text = summary_res.choices[0].message.content
                        st.markdown("---")
                        st.markdown(final_text)
                        st.session_state.messages.append({"role": "assistant", "content": f"{ai_answer}\n\n{final_text}"})
                    else:
                        st.warning("ì¿¼ë¦¬ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        st.session_state.messages.append({"role": "assistant", "content": ai_answer})
                        
                except Exception as e:
                    st.error(f"SQL ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.code(sql) # ì—ëŸ¬ ë‚œ ì¿¼ë¦¬ í™•ì¸ìš©
        else:
            # SQLì´ ìƒì„±ë˜ì§€ ì•Šì€ ì¼ë°˜ ë‹µë³€ì¸ ê²½ìš°
            st.markdown(ai_answer)
            st.session_state.messages.append({"role": "assistant", "content": ai_answer})
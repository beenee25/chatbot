import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="MKT Performance AI Analyst", layout="wide")
st.title("ğŸš€ ë§ˆì¼€íŒ… ì„±ê³¼ ìƒì„¸ ë¶„ì„ê¸°")

# 2. í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìºì‹±)
@st.cache_resource
def get_clients():
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    ai_client = OpenAI(
        base_url="https://api.groq.com/openai/v1",
        api_key=st.secrets["GROQ_API_KEY"]
    )
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# 3. ì‚¬ì´ë“œë°” ê´€ë¦¬
with st.sidebar:
    st.header("âš™ï¸ ê´€ë¦¬ ë„êµ¬")
    if st.button("ğŸ”„ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
    st.info("ëŒ€ìƒ í…Œì´ë¸”: `com2us-bigquery.MKT_AI.marketing_performance`")
    st.write("ğŸ’¡ íŒ: ì»¬ëŸ¼ëª… ë’¤ì— '0'ì´ ë¶™ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë‹ˆ í™•ì¸ í›„ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.")

# 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì •í™•í•œ ì»¬ëŸ¼ ë§¤í•‘ ì¶”ê°€)
TABLE_ID = "com2us-bigquery.MKT_AI.marketing_performance"

SYSTEM_PROMPT = f"""ë„ˆëŠ” BigQuery ì „ë¬¸ê°€ì´ì ë§ˆì¼€íŒ… ë¶„ì„ê°€ì•¼.
[í•„ìˆ˜ SQL ê·œì¹™]
1. í…Œì´ë¸”ëª…: `{TABLE_ID}`
2. **ì¤‘ìš” ì»¬ëŸ¼ ë§¤í•‘**:
   - ë§¤ì¶œ/ìˆ˜ìµ(Revenue)ì€ revenue0, revenue7, revenue14 ë“±ì´ ìˆìœ¼ë©° cohort_dateë¡œë¶€í„° nì¼ì°¨ì˜ ëˆ„ì ëœ ë§¤ì¶œì´ë‹¤.
   - ymdkstëŠ” cohort_dateì´ê³ , revenueì€ í•´ë‹¹ ë‚ ì§œì˜ ë§¤ì¶œì„ ì˜ë¯¸í•´.
   - ë¹„ìš©(Spend/Cost)ì€ `cost_cohort` ì»¬ëŸ¼ì„ ì‚¬ìš©í•´ë¼.
   - ì‹œê°„ ë°ì´í„°ëŠ” `ymdkst` (DATE íƒ€ì…)ë¥¼ ì‚¬ìš©í•´ë¼.
   - ìº í˜ì¸ì€ campaign ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ë¼.
3. ì ˆëŒ€ ëŒ€ê´„í˜¸([])ë¥¼ ì“°ì§€ ë§ê³  ë°±í‹±(`)ì„ ì‚¬ìš©í•´ë¼.
4. SQL ë‚´ë¶€ì— í•œê¸€ ì£¼ì„ì„ ë‹¬ì§€ ë§ˆë¼.
5. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ```sql [ì½”ë“œ] ``` í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ë¼.
6. ëª¨ë“  ì‘ë‹µì˜ ì–¸ì–´ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ë©°, ê³ ìœ  ëª…ì‚¬ì˜ ê²½ìš° ì˜ì–´ë¥¼ í—ˆìš©í•œë‹¤.
7. ì ˆëŒ€ í•œì(æ¼¢å­—)ë¥¼ ì„ì–´ì„œ ì‚¬ìš©í•˜ì§€ ë§ˆë¼.
8. ìˆ«ìëŠ” ì§€ìˆ˜ë¡œ ì•„ë˜ì™€ ê°™ì´ í‘œê¸°í•˜ë©°, ì†Œìˆ«ì ì€ ë²„ë¦°ë‹¤.
  - 1,000 = 1ì²œ,
  - 10,000 = 1ë§Œ
  - 150,000,000 = 1.5ì–µ
9. **ë‚˜ëˆ—ì…ˆ ì˜¤ë¥˜ ë°©ì§€**: ROAS, CTR ë“± ëª¨ë“  ë‚˜ëˆ—ì…ˆ ì—°ì‚° ì‹œ ë°˜ë“œì‹œ `SAFE_DIVIDE(ë¶„ì, ë¶„ëª¨)` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ë¼. ì ˆëŒ€ `/` ê¸°í˜¸ë¥¼ ì§ì ‘ ì“°ì§€ ë§ˆë¼.
   - ì˜ˆ: `SAFE_DIVIDE(SUM(revenue0), SUM(spend0))`
"""

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 5. ë©”ì¸ ë¡œì§
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë‚ ì§œë³„ revenue0 ì¶”ì´ë¥¼ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # í† í° ìµœì í™”: ìµœê·¼ 2ê°œì˜ ë©”ì‹œì§€ë§Œ ì°¸ì¡°
        input_messages = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages[-2:]

        try:
            # 1ë‹¨ê³„: AIì—ê²Œ SQL ìƒì„± ìš”ì²­
            response = client_ai.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=input_messages,
                temperature=0
            )
            ai_answer = response.choices[0].message.content
            
            if "```sql" in ai_answer:
                sql = ai_answer.split("```sql")[1].split("```")[0].strip()
                
                with st.status("BigQuery ë¶„ì„ ì¤‘..."):
                    query_job = client_bq.query(sql)
                    df = query_job.result().to_dataframe(create_bqstorage_client=False)
                
                if not df.empty:
                    st.subheader("ğŸ“ˆ ì‹œê°í™” ë¶„ì„")
                    
                    try:
                        # ì‹œê³„ì—´ ê°ì§€ ë° ê·¸ë˜í”„ ìƒì„±
                        time_cols = [c for c in df.columns if any(k in c.lower() for k in ['ymdkst', 'time', 'date', 'dt'])]
                        if time_cols:
                            t_col = time_cols[0]
                            df[t_col] = pd.to_datetime(df[t_col], errors='coerce')
                            df = df.dropna(subset=[t_col]).sort_values(t_col)
                            st.line_chart(df.set_index(t_col).select_dtypes(include=['number']))
                        elif len(df.columns) >= 2:
                            st.bar_chart(data=df, x=df.columns[0], y=df.columns[1:])
                    except Exception:
                        st.info("ë°ì´í„° êµ¬ì¡°ìƒ ìë™ ê·¸ë˜í”„ ìƒì„±ì´ ì–´ë µìŠµë‹ˆë‹¤. í‘œ ë°ì´í„°ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

                    # ìƒì„¸ ë°ì´í„° í‘œ ì¶œë ¥
                    st.subheader("ğŸ“„ ìƒì„¸ ë°ì´í„°")
                    st.dataframe(df, use_container_width=True)

                    # 3ë‹¨ê³„: AI ìš”ì•½
                    summary_res = client_ai.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[{"role": "user", "content": f"ë°ì´í„° ê²°ê³¼ ìš”ì•½: {df.head(5).to_string()}"}]
                    )
                    final_text = summary_res.choices[0].message.content
                    st.markdown("---")
                    st.markdown(final_text)
                    st.session_state.messages.append({"role": "assistant", "content": final_text})
                else:
                    st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown(ai_answer)
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            if "sql" in locals():
                st.code(sql, language="sql")
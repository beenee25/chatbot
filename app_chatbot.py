import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="BigQuery Analyst with Charts", layout="wide")
st.title("ğŸ“Š ë§¤ì¶œ ë¶„ì„ AI ì±—ë´‡ (ê·¸ë˜í”„ ëª¨ë“œ)")

# 2. í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìºì‹±)
@st.cache_resource
def get_clients():
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    ai_client = OpenAI(
        base_url="https://api.groq.com/openai/v1",
        api_key=st.secrets["GROQ_API_KEY"]
    )
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# 3. ì‚¬ì´ë“œë°” ê´€ë¦¬
with st.sidebar:
    st.header("âš™ï¸ ê´€ë¦¬ ë„êµ¬")
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
    st.info("ëŒ€ìƒ í…Œì´ë¸”: `dummy_sales_data` (date, title, sales, pu)")

# 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê·¸ë˜í”„ ì§€ì¹¨ ì¶”ê°€)
SYSTEM_PROMPT = """ë„ˆëŠ” BigQuery ì „ë¬¸ê°€ì•¼.
1. í…Œì´ë¸”: `com2us-bigquery.MKT_AI.dummy_sales_data`
2. SQL ìƒì„± ì‹œ ë°˜ë“œì‹œ ```sql [ì½”ë“œ] ``` í˜•ì‹ì„ ì§€ì¼œë¼.
3. ì‚¬ìš©ìê°€ ì¶”ì´ë‚˜ ë³€í™”ë¥¼ ë¬¼ì–´ë³´ë©´ ë°˜ë“œì‹œ date ì»¬ëŸ¼ì„ í¬í•¨í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ì§œë¼.
"""

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ë©”ì¸ ë¡œì§
if prompt := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš” (ì˜ˆ: 2025ë…„ ì›”ë³„ ë§¤ì¶œ ê·¸ë˜í”„ ê·¸ë ¤ì¤˜)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # í† í° ìµœì í™” í˜¸ì¶œ
        input_messages = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages[-2:]

        try:
            # 1ë‹¨ê³„: SQL ìƒì„±
            response = client_ai.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=input_messages,
                temperature=0
            )
            ai_answer = response.choices[0].message.content
            
            if "```sql" in ai_answer:
                sql = ai_answer.split("```sql")[1].split("```")[0].strip()
                
                with st.status("ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ì¤‘..."):
                    query_job = client_bq.query(sql)
                    df = query_job.result().to_dataframe(create_bqstorage_client=False)
                    
                    if not df.empty:
                        # --- ê·¸ë˜í”„ ìë™ ì¶œë ¥ ë¡œì§ ---
                        # 1. ì‹œê³„ì—´ ë°ì´í„°(date)ê°€ í¬í•¨ëœ ê²½ìš° ì„  ê·¸ë˜í”„
                        if 'date' in df.columns:
                            df['date'] = pd.to_datetime(df['date'])
                            df_chart = df.set_index('date')
                            st.line_chart(df_chart[['sales']] if 'sales' in df.columns else df_chart)
                        
                        # 2. ì¹´í…Œê³ ë¦¬(title)ë³„ ë°ì´í„°ì¸ ê²½ìš° ë°” ì°¨íŠ¸
                        elif 'title' in df.columns and 'sales' in df.columns:
                            st.bar_chart(data=df, x='title', y='sales')
                        
                        # í‘œë„ í•¨ê»˜ ì¶œë ¥
                        st.dataframe(df, use_container_width=True)
                        # ----------------------------

                        # 3ë‹¨ê³„: ê²°ê³¼ ìš”ì•½
                        summary_res = client_ai.chat.completions.create(
                            model="llama-3.3-70b-versatile",
                            messages=[{"role": "user", "content": f"ì´ ë°ì´í„° ìš”ì•½í•´ì¤˜: {df.head(5).to_string()}"}]
                        )
                        final_text = summary_res.choices[0].message.content
                        st.markdown(final_text)
                        st.session_state.messages.append({"role": "assistant", "content": final_text})
            else:
                st.markdown(ai_answer)
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
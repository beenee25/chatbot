import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="MKT Performance AI Analyst", layout="wide")
st.title("ğŸš€ ë§ˆì¼€íŒ… ì„±ê³¼ ìƒì„¸ ë¶„ì„ê¸° (ymdkst)")

# 2. í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìºì‹±)
@st.cache_resource
def get_clients():
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    ai_client = OpenAI(
        base_url="https://api.groq.com/openai/v1",
        api_key=st.secrets["GROQ_API_KEY"]
    )
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# 3. ì‚¬ì´ë“œë°” ê´€ë¦¬
with st.sidebar:
    st.header("âš™ï¸ ê´€ë¦¬ ë„êµ¬")
    if st.button("ğŸ”„ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
    st.info("ëŒ€ìƒ í…Œì´ë¸”: `com2us-bigquery.MKT_AI.marketing_performance` (ì˜ˆì‹œ)")
    st.write("ì»¬ëŸ¼ êµ¬ì„±: ymdkst, title, spend, click, conversion ë“±")

# 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (BigQuery ë¬¸ë²• ë° ymdkst ì²˜ë¦¬ ê°•í™”)
# TABLE_IDëŠ” ì‹¤ì œ í™˜ê²½ì— ë§ì¶° ìˆ˜ì •í•˜ì„¸ìš”.
TABLE_ID = "com2us-bigquery.MKT_AI.dummy_sales_data"

SYSTEM_PROMPT = f"""ë„ˆëŠ” BigQuery SQL ì „ë¬¸ê°€ì´ì ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ê°€ì•¼.
[í•„ìˆ˜ SQL ê·œì¹™]
1. í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ëª…ì— ì ˆëŒ€ ëŒ€ê´„í˜¸([])ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆë¼. ëŒ€ì‹  ë°±í‹±(`)ì„ ì‚¬ìš©í•´ë¼.
   - ì˜ëª»ëœ ì˜ˆ: [project.dataset.table]
   - ì˜¬ë°”ë¥¸ ì˜ˆ: `{TABLE_ID}`
2. SQL ë‚´ë¶€ì— í•œê¸€ ì£¼ì„ì„ ë‹¬ì§€ ë§ˆë¼.
3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ```sql [ì½”ë“œ] ``` í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ë¼.

[ë°ì´í„° ê°€ì´ë“œ]
- í…Œì´ë¸”ëª…: `{TABLE_ID}`
- ì‹œê°„ ì»¬ëŸ¼: `ymdkst` (í˜•ì‹: YYYYMMDDHHMMSS)
- ì‹œê³„ì—´ ë¶„ì„ ì‹œ `PARSE_TIMESTAMP('%Y%m%d%H%M%S', ymdkst)`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì„ ì²˜ë¦¬í•´ë¼.
"""

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ê¸°ë¡ ì¶œë ¥ (ìµœê·¼ ëŒ€í™” ìœ„ì£¼)
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ë©”ì¸ ë¡œì§
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ìµœê·¼ 24ì‹œê°„ ë™ì•ˆì˜ í´ë¦­ ìˆ˜ ì¶”ì´ ë³´ì—¬ì¤˜)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # í† í° ìµœì í™”: ìµœê·¼ 2ê°œì˜ ëŒ€í™”ë§Œ ì°¸ì¡°
        input_messages = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages[-2:]

        try:
            # 1ë‹¨ê³„: SQL ìƒì„±
            response = client_ai.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=input_messages,
                temperature=0
            )
            ai_answer = response.choices[0].message.content
            
            if "```sql" in ai_answer:
                sql = ai_answer.split("```sql")[1].split("```")[0].strip()
                
                with st.status("BigQuery ë°ì´í„° ë¶„ì„ ì¤‘..."):
                    # 2ë‹¨ê³„: ë°ì´í„° ì¡°íšŒ (Storage API ê¶Œí•œ ì—ëŸ¬ ë°©ì§€)
                    df = client_bq.query(sql).result().to_dataframe(create_bqstorage_client=False)
                
                if not df.empty:
                    st.subheader("ğŸ“ˆ ì‹œê°í™” ë¶„ì„")
                    
                    # ì‹œê³„ì—´ ì²˜ë¦¬ ë¡œì§
                    try:
                        # ymdkst ë˜ëŠ” ì‹œê°„ ê´€ë ¨ ì»¬ëŸ¼ ìë™ ê°ì§€ ë° ë³€í™˜
                        time_cols = [c for c in df.columns if 'time' in c.lower() or 'ymdkst' in c.lower()]
                        if time_cols:
                            t_col = time_cols[0]
                            # ymdkst ë¬¸ìì—´ í˜•ì‹ì„ datetimeìœ¼ë¡œ ë³€í™˜ ì‹œë„
                            df[t_col] = pd.to_datetime(df[t_col], format='%Y%m%d%H%M%S', errors='coerce').fillna(pd.to_datetime(df[t_col], errors='coerce'))
                            df = df.dropna(subset=[t_col]).sort_values(t_col)
                            st.line_chart(df.set_index(t_col).select_dtypes(include=['number']))
                        elif len(df.columns) >= 2:
                            st.bar_chart(data=df, x=df.columns[0], y=df.columns[1:])
                    except Exception as e:
                        st.info("ê¸°ë³¸ ê·¸ë˜í”„ ìƒì„±ì´ ë¶ˆê°€ëŠ¥í•œ ë°ì´í„° êµ¬ì¡°ì…ë‹ˆë‹¤. ì•„ë˜ í‘œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

                    # í‘œ ì¶œë ¥
                    st.subheader("ğŸ“„ ìƒì„¸ ë°ì´í„°")
                    st.dataframe(df, use_container_width=True)

                    # 3ë‹¨ê³„: ìš”ì•½ ë‹µë³€
                    summary_res = client_ai.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[{"role": "user", "content": f"ì´ ë°ì´í„° ìš”ì•½í•´ì¤˜: {df.head(5).to_string()}"}]
                    )
                    final_text = summary_res.choices[0].message.content
                    st.markdown("---")
                    st.markdown(final_text)
                    st.session_state.messages.append({"role": "assistant", "content": final_text})
                else:
                    st.warning("ì¡°íšŒëœ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown(ai_answer)
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})

        except Exception as e:
            st.error(f"ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ: {e}")
            if "sql" in locals():
                st.code(sql, language="sql")
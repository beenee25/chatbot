import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

st.set_page_config(page_title="BigQuery AI Analyst", layout="wide")
st.title("ì§€ëŠ¥í˜• ë°ì´í„° ë¶„ì„ ì±—ë´‡ ğŸ¤–ğŸ“Š")

# 1. í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
@st.cache_resource
def get_clients():
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    ai_client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=st.secrets["GROQ_API_KEY"])
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# 2. ë¶„ì„í•  í…Œì´ë¸” ì •ë³´ (AIê°€ ì¿¼ë¦¬ë¥¼ ì§¤ ìˆ˜ ìˆê²Œ ê°€ì´ë“œë¥¼ ì¤ë‹ˆë‹¤)
TABLE_SCHEMA = """
Table Name: `com2us-bigquery.MKT_AI.cv_creative_image_features`
Columns:
- image_name: ì´ë¯¸ì§€ ê³ ìœ  ID
- tone_dark_ratio: ì–´ë‘ìš´ í†¤ ë¹„ìœ¨ (0~1 ì‚¬ì´ ìˆ˜ì¹˜))
"""

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": f"ë„ˆëŠ” BigQuery ì „ë¬¸ê°€ì•¼. ë‹¤ìŒ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜í•˜ê³  ë¶„ì„í•´ì¤˜. SQLì„ ì‘ì„±í•  ë•ŒëŠ” ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```sql ... ```)ì„ ì‚¬ìš©í•´. \n\nìŠ¤í‚¤ë§ˆ ì •ë³´: {TABLE_SCHEMA}"}]

# ëŒ€í™” ì¶œë ¥ (ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì œì™¸)
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 3. ì‚¬ìš©ì ì…ë ¥ ë° ì²˜ë¦¬
if prompt := st.chat_input("ë°ì´í„°ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # STEP 1: AIì—ê²Œ SQL ìƒì„±ì„ ìš”ì²­
        response = client_ai.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=st.session_state.messages
        )
        ai_answer = response.choices[0].message.content
        
        # STEP 2: ìƒì„±ëœ ë‹µë³€ì—ì„œ SQL ì¶”ì¶œ ë° ì‹¤í–‰
        if "```sql" in ai_answer:
            sql = ai_answer.split("```sql")[1].split("```")[0].strip()
            
            with st.status("BigQuery ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘..."):
                try:
                    df = client_bq.query(sql).to_dataframe()
                    st.dataframe(df) # ë°ì´í„° ê²°ê³¼ í‘œë¡œ ë³´ì—¬ì£¼ê¸°
                    
                    # STEP 3: ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… í•´ì„ ìš”ì²­
                    analysis_prompt = f"ìœ„ ë°ì´í„° ê²°ê³¼({df.to_string(index=False)})ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ìµœì¢… ê²°ë¡ ì„ í•œê¸€ë¡œ ìš”ì•½í•´ì¤˜."
                    st.session_state.messages.append({"role": "assistant", "content": ai_answer})
                    st.session_state.messages.append({"role": "user", "content": analysis_prompt})
                    
                    final_res = client_ai.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=st.session_state.messages
                    )
                    final_text = final_res.choices[0].message.content
                    st.markdown(final_text)
                    st.session_state.messages.append({"role": "assistant", "content": final_text})
                    
                except Exception as e:
                    st.error(f"SQL ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                    st.code(sql)
        else:
            # SQLì´ í•„ìš” ì—†ëŠ” ì¼ë°˜ ëŒ€í™”ì¸ ê²½ìš°
            st.markdown(ai_answer)
            st.session_state.messages.append({"role": "assistant", "content": ai_answer})
import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI

st.set_page_config(page_title="BigQuery AI Assistant", layout="wide")
st.title("BigQuery ë°ì´í„° ì±—ë´‡ ğŸ“Š")

# 1. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ìºì‹± ì²˜ë¦¬)
@st.cache_resource
def get_clients():
    # BigQuery ì„¤ì •
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    
    # Groq ì„¤ì • (OpenAI í˜¸í™˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
    ai_client = OpenAI(
        base_url="https://api.groq.com/openai/v1",
        api_key=st.secrets["GROQ_API_KEY"]
    )
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# 2. ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# 3. ì´ì „ ëŒ€í™” ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 5. íŠ¹ìˆ˜ ë¡œì§: BigQuery ì¡°íšŒê°€ í•„ìš”í•œ ê²½ìš°
    context_data = ""
    if "ë§¤ì¶œ" in prompt or "ë°ì´í„°" in prompt:
        with st.status("BigQueryì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘..."):
            try:
                # ì¿¼ë¦¬ ì‹¤í–‰
                query = "SELECT * FROM `com2us-bigquery.MKT_AI.cv_creative_image_features`"
                df = client_bq.query(query).to_dataframe()
                
                st.write("ì¡°íšŒëœ ë°ì´í„° ìƒ˜í”Œ:", df)
                # AIì—ê²Œ ì „ë‹¬í•  ë°ì´í„° í…ìŠ¤íŠ¸í™”
                context_data = f"\n\nì°¸ê³  ë°ì´í„° (BigQuery): \n{df.to_string(index=False)}"
            except Exception as e:
                st.error(f"BigQuery ì—ëŸ¬: {e}")

    # 6. AI ì‘ë‹µ ìƒì„± (ë°ì´í„°ê°€ ìˆìœ¼ë©´ í¬í•¨í•´ì„œ ì§ˆë¬¸)
    with st.chat_message("assistant"):
        # ë§ˆì§€ë§‰ ìœ ì € ì§ˆë¬¸ì— ë°ì´í„° ì •ë³´ ì¶”ê°€ (í•„ìš”í•œ ê²½ìš°ë§Œ)
        current_messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
        if context_data:
            current_messages[-1]["content"] += context_data

        stream = client_ai.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=current_messages,
            stream=True,
        )
        response = st.write_stream(stream)
    
    # AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": response})
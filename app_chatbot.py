import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

st.set_page_config(page_title="Com2uS Data Analyst", layout="wide")
st.title("ğŸ“Š ë§¤ì¶œ ë°ì´í„° í†µí•© ë¶„ì„ê¸°")

@st.cache_resource
def get_clients():
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    ai_client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=st.secrets["GROQ_API_KEY"])
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
    st.info("ëŒ€ìƒ: `dummy_sales_data` (date, title, sales, pu)")

# --- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì‹œê°í™” ìµœì í™” ì¿¼ë¦¬ ìœ ë„) ---
SYSTEM_PROMPT = """ë„ˆëŠ” BigQuery ì „ë¬¸ê°€ì•¼. 
- í…Œì´ë¸”: `com2us-bigquery.MKT_AI.dummy_sales_data`
- ì‚¬ìš©ìê°€ ì¶”ì´ë‚˜ ë¹„êµë¥¼ ë¬¼ì–´ë³´ë©´ ë°˜ë“œì‹œ Xì¶•ìœ¼ë¡œ ì“¸ ì»¬ëŸ¼(date í˜¹ì€ title)ê³¼ Yì¶•ìœ¼ë¡œ ì“¸ ìˆ˜ì¹˜ ì»¬ëŸ¼(sales, pu)ì„ í•¨ê»˜ ì¡°íšŒí•´ë¼.
- SQLë§Œ ìƒì„±í•˜ê³  í•œê¸€ ì£¼ì„ì€ ë‹¬ì§€ ë§ˆë¼."""

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- ë©”ì¸ ë¡œì§ ---
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        input_messages = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages[-2:]

        try:
            response = client_ai.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=input_messages,
                temperature=0
            )
            ai_answer = response.choices[0].message.content
            
            if "```sql" in ai_answer:
                sql = ai_answer.split("```sql")[1].split("```")[0].strip()
                
                with st.status("ë°ì´í„° ë¶„ì„ ì¤‘..."):
                    df = client_bq.query(sql).result().to_dataframe(create_bqstorage_client=False)
                
                if not df.empty:
                    st.subheader("ğŸ“ˆ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”")
                    
                    # 1. ì‹œê°í™” ì‹œë„
                    try:
                        # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‹œê³„ì—´ë¡œ ë³€í™˜
                        date_cols = [c for c in df.columns if 'date' in c.lower() or 'dt' in c.lower()]
                        if date_cols:
                            df[date_cols[0]] = pd.to_datetime(df[date_cols[0]])
                            chart_df = df.set_index(date_cols[0])
                            st.line_chart(chart_df)
                        # ë¬¸ìì—´(title)ê³¼ ìˆ«ì ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ë°” ì°¨íŠ¸
                        elif len(df.columns) >= 2:
                            st.bar_chart(data=df, x=df.columns[0], y=df.columns[1:])
                    except Exception:
                        st.info("ë°ì´í„° íŠ¹ì„±ìƒ ê·¸ë˜í”„ ìƒì„±ì´ ê±´ë„ˆë›°ì–´ì¡ŒìŠµë‹ˆë‹¤.")

                    # 2. ë°ì´í„° í‘œ ë¬´ì¡°ê±´ ì¶œë ¥ (ê·¸ë˜í”„ ë°”ë¡œ ì•„ë˜)
                    st.subheader("ğŸ“„ ìƒì„¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸")
                    st.dataframe(df, use_container_width=True)

                    # 3. ìš”ì•½ ë‹µë³€
                    summary_res = client_ai.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[{"role": "user", "content": f"ì´ ë°ì´í„° ê²°ê³¼({df.head(5).to_string()})ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìš”ì•½í•´ì¤˜."}]
                    )
                    st.markdown("---")
                    st.markdown(summary_res.choices[0].message.content)
                    st.session_state.messages.append({"role": "assistant", "content": summary_res.choices[0].message.content})
            else:
                st.markdown(ai_answer)
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
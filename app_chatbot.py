import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="MKT Performance AI", layout="wide")
st.title("ğŸš€ ë§ˆì¼€íŒ… ì„±ê³¼ ë¶„ì„ê¸° (DATE íƒ€ì… ìµœì í™”)")

# 2. í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìºì‹±)
@st.cache_resource
def get_clients():
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    ai_client = OpenAI(
        base_url="https://api.groq.com/openai/v1",
        api_key=st.secrets["GROQ_API_KEY"]
    )
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# 3. ì‚¬ì´ë“œë°” ê´€ë¦¬
with st.sidebar:
    st.header("âš™ï¸ ê´€ë¦¬ ë„êµ¬")
    if st.button("ğŸ”„ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()
    st.info("ëŒ€ìƒ í…Œì´ë¸”: `com2us-bigquery.MKT_AI.marketing_performance`")
    st.write("ì°¸ê³ : `ymdkst` ì»¬ëŸ¼ì€ ì´ë¯¸ DATE/TIMESTAMP í˜•ì‹ì´ë¯€ë¡œ ë³„ë„ ë³€í™˜ì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤.")

# 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (DATE íƒ€ì… ëŒ€ì‘ ë° ë¬¸ë²• ê³ ì •)
TABLE_ID = "com2us-bigquery.MKT_AI.marketing_performance"

SYSTEM_PROMPT = f"""ë„ˆëŠ” BigQuery ì „ë¬¸ê°€ì•¼.
[í•„ìˆ˜ ê·œì¹™]
1. í…Œì´ë¸”ëª…: `{TABLE_ID}`
2. ì»¬ëŸ¼ëª…: `ymdkst` (ì´ ì»¬ëŸ¼ì€ ì´ë¯¸ DATE í˜¹ì€ TIMESTAMP íƒ€ì…ì´ë‹¤).
3. **ì¤‘ìš”**: `ymdkst`ì— `PARSE_TIMESTAMP` í•¨ìˆ˜ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆë¼. ì´ë¯¸ ë‚ ì§œ í˜•ì‹ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ í•„ìš”í•œ ê²½ìš° `CAST(ymdkst AS TIMESTAMP)`ë§Œ ì‚¬ìš©í•´ë¼.
4. í…Œì´ë¸”/ì»¬ëŸ¼ëª…ì„ ê°ìŒ€ ë•Œ ì ˆëŒ€ ëŒ€ê´„í˜¸([])ë¥¼ ì“°ì§€ ë§ê³  ë°±í‹±(`)ì„ ì‚¬ìš©í•´ë¼.
5. SQL ë‚´ë¶€ì— í•œê¸€ ì£¼ì„ì„ ë‹¬ì§€ ë§ˆë¼.
6. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ```sql [ì½”ë“œ] ``` í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ë¼.
"""

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 5. ë©”ì¸ ë¡œì§
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë‚ ì§œë³„ spendì™€ click ì¶”ì´ë¥¼ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # í† í° ìµœì í™”: ìµœê·¼ 2ê°œì˜ ë©”ì‹œì§€ë§Œ ì°¸ì¡°
        input_messages = [{"role": "system", "content": SYSTEM_PROMPT}] + st.session_state.messages[-2:]

        try:
            # 1ë‹¨ê³„: AIì—ê²Œ SQL ìƒì„± ìš”ì²­
            response = client_ai.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=input_messages,
                temperature=0
            )
            ai_answer = response.choices[0].message.content
            
            if "```sql" in ai_answer:
                sql = ai_answer.split("```sql")[1].split("```")[0].strip()
                
                with st.status("BigQuery ë¶„ì„ ì¤‘..."):
                    # 2ë‹¨ê³„: ë°ì´í„° ì¡°íšŒ (Storage API ë¯¸ì‚¬ìš© ì˜µì…˜ìœ¼ë¡œ ê¶Œí•œ ì—ëŸ¬ ë°©ì§€)
                    query_job = client_bq.query(sql)
                    df = query_job.result().to_dataframe(create_bqstorage_client=False)
                
                if not df.empty:
                    st.subheader("ğŸ“ˆ ì‹œê°í™” ë¶„ì„")
                    
                    # ì‹œê³„ì—´ ê·¸ë˜í”„ ë¡œì§ (ë‚ ì§œ í˜•ì‹ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬)
                    try:
                        # ymdkst ë˜ëŠ” ì‹œê°„ ê´€ë ¨ ì»¬ëŸ¼ ìë™ ê°ì§€
                        time_cols = [c for c in df.columns if any(k in c.lower() for k in ['ymdkst', 'time', 'date', 'dt'])]
                        if time_cols:
                            t_col = time_cols[0]
                            df[t_col] = pd.to_datetime(df[t_col], errors='coerce')
                            df = df.dropna(subset=[t_col]).sort_values(t_col)
                            # ìˆ«ìí˜• ë°ì´í„°ë§Œ ê·¸ë˜í”„ë¡œ í‘œì‹œ
                            st.line_chart(df.set_index(t_col).select_dtypes(include=['number']))
                        elif len(df.columns) >= 2:
                            st.bar_chart(data=df, x=df.columns[0], y=df.columns[1:])
                    except Exception as chart_err:
                        st.info("ë°ì´í„° êµ¬ì¡°ìƒ ìë™ ê·¸ë˜í”„ ìƒì„±ì´ ì–´ë µìŠµë‹ˆë‹¤. í‘œ ë°ì´í„°ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")

                    # ìƒì„¸ ë°ì´í„° í‘œ ì¶œë ¥
                    st.subheader("ğŸ“„ ìƒì„¸ ë°ì´í„°")
                    st.dataframe(df, use_container_width=True)

                    # 3ë‹¨ê³„: AI ìš”ì•½
                    # í† í° ì ˆì•½ì„ ìœ„í•´ head(5)ë§Œ ì „ë‹¬
                    summary_res = client_ai.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[{"role": "user", "content": f"ë°ì´í„° ê²°ê³¼ ìš”ì•½: {df.head(5).to_string()}"}]
                    )
                    final_text = summary_res.choices[0].message.content
                    st.markdown("---")
                    st.markdown(final_text)
                    st.session_state.messages.append({"role": "assistant", "content": final_text})
                else:
                    st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown(ai_answer)
                st.session_state.messages.append({"role": "assistant", "content": ai_answer})

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            if "sql" in locals():
                st.code(sql, language="sql")
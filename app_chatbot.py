import streamlit as st
from google.oauth2 import service_account
from google.cloud import bigquery
from openai import OpenAI
import pandas as pd

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Com2uS BigData Analyst", layout="wide")
st.title("ğŸ“Š Com2uS ëŒ€ê·œëª¨ í”¼ì²˜ ë¶„ì„ê¸°")

# 2. í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ìºì‹±)
@st.cache_resource
def get_clients():
    # Secretsì— gcp_service_accountì™€ GROQ_API_KEYê°€ ë“±ë¡ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    credentials = service_account.Credentials.from_service_account_info(st.secrets["gcp_service_account"])
    bq_client = bigquery.Client(credentials=credentials, project=credentials.project_id)
    
    ai_client = OpenAI(
        base_url="https://api.groq.com/openai/v1",
        api_key=st.secrets["GROQ_API_KEY"]
    )
    return bq_client, ai_client

client_bq, client_ai = get_clients()

# 3. ì‚¬ì´ë“œë°”: 550ê°œ ì»¬ëŸ¼ ì¤‘ ì›í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸° ê¸°ëŠ¥
with st.sidebar:
    st.header("ğŸ” ì»¬ëŸ¼ ì‚¬ì „ ê²€ìƒ‰")
    st.info("550ê°œì˜ ì»¬ëŸ¼ ì¤‘ ì •í™•í•œ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
    search_keyword = st.text_input("ì°¾ê³  ì‹¶ì€ í‚¤ì›Œë“œ (ì˜ˆ: ratio, score, dark)")
    
    if search_keyword:
        col_search_query = f"""
            SELECT column_name, data_type 
            FROM `com2us-bigquery.MKT_AI.INFORMATION_SCHEMA.COLUMNS` 
            WHERE table_name = 'cv_creative_image_features' 
            AND (column_name LIKE '%{search_keyword}%')
            LIMIT 20
        """
        try:
            found_cols = client_bq.query(col_search_query).to_dataframe()
            if not found_cols.empty:
                st.dataframe(found_cols, hide_index=True)
            else:
                st.warning("í•´ë‹¹ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

# 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì „ëµì  ì§€ì¹¨)
TABLE_ID = "com2us-bigquery.MKT_AI.cv_creative_image_features"
SYSTEM_MESSAGE = {
    "role": "system",
    "content": f"""ë„ˆëŠ” BigQuery SQL ìƒì„± ì „ë¬¸ê°€ì´ë‹¤. 
    ì´ í…Œì´ë¸”ì€ ì»¬ëŸ¼ì´ 550ê°œì´ë¯€ë¡œ, ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ëª…ì„ ì¶”ì¸¡í•˜ì§€ ë§ˆë¼.

    [í•µì‹¬ ê·œì¹™]
    1. ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ë‹¨ì–´ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì˜ë¬¸ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì—¬ SQLì„ ì‘ì„±í•´ë¼.
    2. ë§Œì•½ ì»¬ëŸ¼ëª…ì´ í™•ì‹¤í•˜ì§€ ì•Šë‹¤ë©´, ì‚¬ìš©ìì—ê²Œ ì‚¬ì´ë“œë°”ì—ì„œ ì»¬ëŸ¼ì„ ê²€ìƒ‰í•´ë‹¬ë¼ê³  ìš”ì²­í•˜ê±°ë‚˜, 
       ì•„ë˜ ì¿¼ë¦¬ë¥¼ í†µí•´ ì§ì ‘ ì»¬ëŸ¼ ëª©ë¡ì„ í™•ì¸í•˜ë¼ê³  ë‹µë³€í•´ë¼.
       ```sql
       SELECT column_name FROM `com2us-bigquery.MKT_AI.INFORMATION_SCHEMA.COLUMNS` WHERE table_name = 'cv_creative_image_features' AND column_name LIKE '%í‚¤ì›Œë“œ%'
       ```
    3. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ```sql [ì½”ë“œ] ``` ë¸”ë¡ì„ ì‚¬ìš©í•˜ê³ , í•œê¸€ ì£¼ì„ì€ ì ˆëŒ€ ë‹¬ì§€ ë§ˆë¼.
    4. í…Œì´ë¸”ëª…: `{TABLE_ID}`
    """
}

# ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = [SYSTEM_MESSAGE]

for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# 5. ë©”ì¸ ì±„íŒ… ë¡œì§
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: tone_dark_ratioê°€ ë†’ì€ ì´ë¯¸ì§€ 5ê°œ)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # AIì—ê²Œ SQL ìƒì„± ìš”ì²­
        response = client_ai.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=st.session_state.messages,
            temperature=0
        )
        ai_answer = response.choices[0].message.content
        
        # SQL ë¸”ë¡ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if "```sql" in ai_answer:
            sql = ai_answer.split("```sql")[1].split("```")[0].strip()
            
            with st.status("BigQuery ì‹¤í–‰ ì¤‘..."):
                try:
                    df = client_bq.query(sql).to_dataframe()
                    st.dataframe(df)
                    
                    # ë°ì´í„° ê¸°ë°˜ ìš”ì•½ ìš”ì²­
                    summary_prompt = f"ì¡°íšŒëœ ë°ì´í„° ìƒ˜í”Œ: {df.head(5).to_string()}\n\nì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œê¸€ë¡œ ìš”ì•½ ë‹µë³€í•´ì¤˜."
                    summary_res = client_ai.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[{"role": "user", "content": summary_prompt}]
                    )
                    final_text = summary_res.choices[0].message.content
                    st.markdown(final_text)
                    st.session_state.messages.append({"role": "assistant", "content": f"{ai_answer}\n\n{final_text}"})
                except Exception as e:
                    st.error(f"SQL ì—ëŸ¬ ë°œìƒ: {e}")
                    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì •í™•í•œ ì»¬ëŸ¼ëª…ì„ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.")
                    st.code(sql)
        else:
            # SQLì´ ì—†ëŠ” ì¼ë°˜ ëŒ€í™”
            st.markdown(ai_answer)
            st.session_state.messages.append({"role": "assistant", "content": ai_answer})